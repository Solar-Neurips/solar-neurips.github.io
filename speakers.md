---
layout: page
title: Speakers & Panelists
subtitle: 
---
 
<div class='row'>
  <div class="col-3">
    <div class="frame">
      <img class="speaker-img" src='/assets/img/been.jpg'>
    </div>
  </div>
  <div class="col-9">
    <h4><a href="https://beenkim.github.io">Been Kim</a></h4>
    <p class='speaker-affiliation'>Senior Staff Research Scientist at Google Deepmind</p>
    <p style='font-size: 11pt;'>
      <b>Speaker</b>
    </p>
       <h5 class="talk-title">Towards Interpretability for Humanity.</h5>
  </div>
</div>

<div class='row'>
  <div class="col-3">
    <div class="frame">
      <img class="speaker-img" src='/assets/img/peter.jpg'>
    </div>
  </div>
  <div class="col-9">
    <h4><a href="https://www.peterhenderson.co/">Peter Henderson</a></h4>
    <p class='speaker-affiliation'>Assistant Professor at Princeton University</p>
    <p style='font-size: 11pt;'>
      <b>Speaker</b>
    </p>
       <h5 class="talk-title">Aligning Machine Learning and Law for Responsible Real-World Deployments</h5>
    <p class="talk-abstract">
Aligning Machine Learning and Law for Responsible Real-World Deployments
Abstract: Machine learning (ML) is being deployed to a vast array of real-world applications with profound impacts on society. ML can have positive impacts, such as aiding in the discovery of new cures for diseases and improving government transparency and efficiency. But it can also be harmful: reinforcing authoritarian regimes, scaling the spread of disinformation, and exacerbating societal biases. As we rapidly move toward systemic use of ML in the real world, there are many unanswered questions about how to successfully use ML for social good while preventing its potential harms. Many of these questions inevitably require pursuing a deeper alignment between ML and law. Are certain algorithms truly compliant with current laws and regulations? Is there a better design that can make them more in tune to the regulatory and policy requirements of the real world? Are laws, policies, and regulations sufficiently informed by the technical details of ML algorithms, or will they be ineffective and out-of-sync? In this talk, I will discuss ways to bring together ML and law together to address these questions. I will draw on real-world examples throughout the talk, including unique real-world collaborations with public sector organizations. I will show how investigating questions of alignment between ML and law can advance core research in ML, as well as creating positive public good impact. It is my hope that the tools discussed in this talk will help us lead to more effective and responsible ways of deploying ML in the real world, so that we steer toward positive impacts of ML.
    </p>
  </div>
</div>

<div class='row'>
  <div class="col-3">
    <div class="frame">
      <img class="speaker-img" src='/assets/img/zico.jpg'>
    </div>
  </div>
  <div class="col-9">
    <h4><a href="https://zicokolter.com">Zico Kolter</a></h4>
    <p class='speaker-affiliation'>Associate Professor, Carnegie Mellon University</p>
    <p style='font-size: 11pt;'>
      <b>Speaker</b>
    </p>
  </div>
</div>

<div class='row'>
  <div class="col-3">
    <div class="frame">
      <img class="speaker-img" src='/assets/img/rida.jpeg' alt="Rida Qadri">
    </div>
  </div>
  <div class="col-9">
    <h4><a href="https://ridaqadri.net">Rida Qadri</a></h4>
    <p class='speaker-affiliation'>Research Scientist at Google</p>
    <p class='speaker-label'>
      <b>Speaker</b>
    </p>
    <h5 class="talk-title">AI's Cultural Futures: Designing for a Culturally Rich World</h5>
    <p class="talk-abstract">
    With global diffusion of AI models, concerns about cultural erasure and Western bias are growing. In this talk, I explore how we can reimagine AI design to celebrate, not erase, the world's cultural richness. My talk focuses on three key aspects of AI design: imagination, evaluation, and interaction. First, I advocate for community-based studies to understand the diverse ways people imagine and engage with AI. By recognizing how communities appropriate and innovate with technology, we can develop more culturally appropriate uses and designs. Second, I challenge the dominance of evaluation metrics that neglect the nuances of social behavior they are seeking to evaluate. Finally, I envision AI interfaces that encourage users to question, critique, and playfully subvert the technology. This fosters a more empowered relationship, allowing users to shape AI in ways that reflect their own values and needs. This talk contributes to a vision of technology design that empowers communities to shape their own technological futures.
    </p>
  </div>
</div>

<div class='row'>
  <div class="col-3">
    <div class="frame">
      <img class="speaker-img" src='/assets/img/hannah_kirk.jpg'>
    </div>
  </div>
  <div class="col-9">
    <h4><a href="https://www.hannahrosekirk.com">Hannah Rose Kirk</a></h4>
    <p class='speaker-affiliation'>Research Scientist at the UK AI Safety Institute</p>
    <p style='font-size: 11pt;'>
      <b>Speaker</b>
         </p>
    <h5 class="talk-title">A Tale of Two RCTs: ​ Building a rigorous evidence base on the societal impacts of frontier AI inside the UK Government</h5>
    <p class="talk-abstract">
  This talk explores how the UK AI Safety Institute's Societal Impacts team is developing empirical evidence on how frontier AI affects human behaviour and beliefs. Drawing from our sociotechnical safety framework—which examines exposure, vulnerability, and severity of AI risks—I'll present two parallel research tracks that combine population-level insights with randomised control trials. The first examines AI's role in political information seeking and belief change, while the second investigates the relationship between AI anthropomorphism, personalisation and behavioural influence. Together, these studies demonstrate build evidence on the mechanisms through which AI systems can influence their users.
    </p>
   </div>
</div>

<div class='row'>
  <div class="col-3">
    <div class="frame">
      <img class="speaker-img" src='/assets/img/margaret.jpg'>
    </div>
  </div>
  <div class="col-9">
    <h4><a href="https://www.m-mitchell.com">Margaret Mitchell</a></h4>
    <p class='speaker-affiliation'>Chief Ethics Scientist, Hugging Face</p>
    <p style='font-size: 11pt;'>
      <b>Panelist</b>
    </p>
  </div>
</div> 

<div class='row'>
  <div class="col-3">
    <div class="frame">
      <img class="speaker-img" src='/assets/img/bengio.jpeg'>
    </div>
  </div>
  <div class="col-9">
    <h4><a href="https://yoshuabengio.org">Yoshua Bengio</a></h4>
    <p class='speaker-affiliation'>Scientific Director of Mila - Quebec AI Institute</p>
    <p style='font-size: 11pt;'>
      <b>Panelist</b>
    </p>
  </div>
</div>

<div class='row'>
  <div class="col-3">
    <div class="frame">
      <img class="speaker-img" src='/assets/img/jeff.jpg'>
    </div>
  </div>
  <div class="col-9">
    <h4><a href="http://jeffclune.com">Jeff Clune</a></h4>
    <p class='speaker-affiliation'>Professor at University of British Columbia</p>
    <p style='font-size: 11pt;'>
      <b>Panelist</b>
    </p>
  </div>
</div>

<div class='row'>
  <div class="col-3">
    <div class="frame">
      <img class="speaker-img" src='/assets/img/jakob.png'>
    </div>
  </div>
  <div class="col-9">
    <h4><a href="https://www.jakobfoerster.com">Jakob Foerster</a></h4>
    <p class='speaker-affiliation'>Associate Professor, University of  Oxford</p>
    <p style='font-size: 11pt;'>
      <b>Panel Moderator</b>
    </p>
  </div>
</div>



