---
layout: page
title: Call for Papers
subtitle: 
---

<h3 style='margin-bottom: 10pt;'>Key Dates</h3>

<div class='description' style='font-size: 11pt;align: center'>

<table style='margin-bottom:10pt;'>
	<tr>
		<td> <b>Submission Deadline</b></td> 
		<td> 26 September, 2022 </td>
	</tr>
	<tr>
		<td> Acceptance Notification </td>
		<td> 14 October, 2022 </td>
	</tr>
	<tr>
		<td> Camera-Ready Deadline</td>
		<td> 16 November, 2022</td>
	</tr>
	<tr>
		<td> Workshop Date</td>
		<td> 2 December, 2022</td>
	</tr>
</table>

<p>All deadlines are specified in <a href="https://www.timeanddate.com/time/zones/aoe" target="_blank">AoE</a> (Anywhere on Earth).
</p>

</div>

<h3 style='margin-bottom: 10pt;'>Topics</h3>

<div class='description' style='font-size: 11pt;'>

As language models (LMs) revolutionize various fields, it becomes critical to ensure their respon-
sible development and deployment. This includes considering factors like alignment, security, and
fairness, while striving for bias-free, misuse-resistant, and interpretable models. Our workshop aims
to encourage a wider discussion on these societal impacts of LMs, promoting more socially conscious
and accountable LM research. We anticipate a broad array of submissions given the multi-faceted
impact of LMs. Our focus areas will include but are not limited to:

<ul>
<li>Security and privacy concerns of LMs [10, 17, 15] </li>
<li>Bias and exclusion in LMs [9, 2] </li>
<li>Analysis of the development and deployment of LMs, including crowdwork [26, 30], deployment protocols [32, 28], and societal impacts from deployment [8, 13]. </li>
<li>Safety, robustness, and alignment of LMs [31, 6, 20, 19] </li>
<li>Auditing, red-teaming, and evaluations of LMs [25, 24, 16] </li>
<li>Transparency, explainability, interpretability of LMs [23, 12, 3, 27, 14, 22] </li>
<li>Applications of LMs for social good, including sector-specific applications [7, 18, 11] and LMs </li>
<li>for low-resource languages [4, 5, 21] </li>
<li>Perspectives from other domains that can inform socially responsible LM development and
deployment [29, 1] </li>
</ul>

We also encourage sociotechnical submissions from other disciplines such as philosophy, law, and
policy, in order to foster an interdisciplinary dialogue on the societal impacts of LMs.

</div>


<h3 style='margin-bottom: 10pt;'>Submission Instructions</h3>

<div class='description' style='font-size: 11pt;'>
<p>Submission should be made on <a href="https://openreview.net/group?id=NeurIPS.cc/2022/Workshop/LaReL" target="_blank">OpenReview</a>.</p>

<p> Submissions should be anonymised papers up to 4 pages (appendices can be added to the main PDF). You must format your submission using the <a href="https://neurips.cc/Conferences/2022/PaperInformation/StyleFiles" target="_blank"> NeurIPS 2022 LaTeX style file </a>. Reviews will be double-blind, with at least two reviewers assigned to each paper.</p> 

<p>The papers should report original research, provide synthesis of previous works or develop novel environments. Short opinion and review papers are welcomed. We accept dual submission. Authors can upload concise versions of parallel submissions to other conferences such as NeurIPS main conference or ICLR. We discourage submitting to multiple NeurIPS workshops</p>

<p>All accepted papers will be available on the workshop website, but no formal workshop proceedings will be published.</p>

<p>For any questions, email us at <a href='mailto:larel.ws@gmail.com'>larel.ws@gmail.com</a>.</p>

<h3 style='margin-bottom: 10pt;'>References</h3>


<div class='references' style='font-size:9pt'>
<p> 
[1] M. Abdalla and M. Abdalla. The Grey Hoodie Project: Big Tobacco, Big Tech, and the Threat
on Academic Integrity. In Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and
Society. ACM, July 2021. doi: 10.1145/3461702.3462563. URL https://doi.org/10.1145%
2F3461702.3462563.
[2] A. Abid, M. Farooqi, and J. Zou. Persistent Anti-Muslim Bias in Large Language Models. In
Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society. ACM, July 2021.
doi: 10.1145/3461702.3462624. URL https://doi.org/10.1145%2F3461702.3462624.
[3] J. Adebayo, M. Muelly, H. Abelson, and B. Kim. Post hoc Explanations may be Ineffec-
tive for Detecting Unknown Spurious Correlation. In International Conference on Learning
Representations, 2022. URL https://openreview.net/forum?id=xNOVfCCvDpM.
[4] D. Adelani, J. Alabi, A. Fan, J. Kreutzer, X. Shen, M. Reid, D. Ruiter, D. Klakow, P. Nabende,
E. Chang, T. Gwadabe, F. Sackey, B. F. P. Dossou, C. Emezue, C. Leong, M. Beukman,
S. Muhammad, G. Jarso, O. Yousuf, A. Niyongabo Rubungo, G. Hacheme, E. P. Waira-
gala, M. U. Nasir, B. Ajibade, T. Ajayi, Y. Gitau, J. Abbott, M. Ahmed, M. Ochieng,
A. Aremu, P. Ogayo, J. Mukiibi, F. Ouoba Kabore, G. Kalipe, D. Mbaye, A. A. Tapo,
V. Memdjokam Koagne, E. Munkoh-Buabeng, V. Wagner, I. Abdulmumin, A. Awokoya,
H. Buzaaba, B. Sibanda, A. Bukula, and S. Manthalu. A Few Thousand Translations Go
a Long Way! Leveraging Pre-trained Models for African News Translation. In Proceedings
of the 2022 Conference of the North American Chapter of the Association for Computational
Linguistics: Human Language Technologies, pages 3053–3070, Seattle, United States, July
2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.naacl-main.223. URL
https://aclanthology.org/2022.naacl-main.223.
[5] D. Adelani, G. Neubig, S. Ruder, S. Rijhwani, M. Beukman, C. Palen-Michel, C. Lignos,
J. Alabi, S. Muhammad, P. Nabende, C. M. B. Dione, A. Bukula, R. Mabuya, B. F. P. Dossou,
B. Sibanda, H. Buzaaba, J. Mukiibi, G. Kalipe, D. Mbaye, A. Taylor, F. Kabore, C. C. Emezue,
A. Aremu, P. Ogayo, C. Gitau, E. Munkoh-Buabeng, V. Memdjokam Koagne, A. A. Tapo,
T. Macucwa, V. Marivate, M. T. Elvis, T. Gwadabe, T. Adewumi, O. Ahia, J. Nakatumba-
Nabende, N. L. Mokono, I. Ezeani, C. Chukwuneke, M. Oluwaseun Adeyemi, G. Q. Hacheme,
I. Abdulmumin, O. Ogundepo, O. Yousuf, T. Moteu, and D. Klakow. MasakhaNER 2.0:
Africa-centric Transfer Learning for Named Entity Recognition. In Proceedings of the 2022
Conference on Empirical Methods in Natural Language Processing, pages 4488–4508, Abu
Dhabi, United Arab Emirates, Dec. 2022. Association for Computational Linguistics. URL
https://aclanthology.org/2022.emnlp-main.298.
[6] Y. Bai, A. Jones, K. Ndousse, A. Askell, A. Chen, N. DasSarma, D. Drain, S. Fort, D. Gan-
guli, T. Henighan, N. Joseph, S. Kadavath, J. Kernion, T. Conerly, S. El-Showk, N. Elhage,
Z. Hatfield-Dodds, D. Hernandez, T. Hume, S. Johnston, S. Kravec, L. Lovitt, N. Nanda,
C. Olsson, D. Amodei, T. Brown, J. Clark, S. McCandlish, C. Olah, B. Mann, and J. Ka-
plan. Training a Helpful and Harmless Assistant with Reinforcement Learning from Human
Feedback, Apr. 2022. URL http://arxiv.org/abs/2204.05862. arXiv:2204.05862 [cs].
[7] M. A. Bakker, M. J. Chadwick, H. Sheahan, M. H. Tessler, L. Campbell-Gillingham, J. Bal-
aguer, N. McAleese, A. Glaese, J. Aslanides, M. Botvinick, and C. Summerfield. Fine-tuning
language models to find agreement among humans with diverse preferences. In A. H. Oh,


</div>

